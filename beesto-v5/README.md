# ğŸ Beesto AI â€” v5.0

A premium, fully client-side AI chatbot with smart file routing, vision analysis, PDF reading, and audio transcription.

## âœ… What's fixed in v5.0

| Issue | Fix |
|-------|-----|
| Vision broken on Groq | Removed `detail` param â€” Groq doesn't support it |
| PDF not analysed | Improved extraction (40pp, 150k chars) with structured context injection |
| Token limits causing 400 errors | Exact per-model limits via `GROQ_MODEL_MAX_TOKENS` map |
| Conflicting animations | Single CSS keyframe source, smooth transitions |
| Image detail on OpenAI | `detail:'high'` applied only to OpenAI/OpenRouter |

## ğŸš€ Quick Start

Just open `index.html` in a browser. No build step, no server needed.

```bash
# Or serve locally:
npx serve .
# or
python3 -m http.server 8080
```

## ğŸ“ Structure

```
beesto-ai/
â”œâ”€â”€ index.html        # Main app (Alpine.js, Tailwind CDN)
â”œâ”€â”€ js/
â”‚   â””â”€â”€ app.js        # All logic â€” routing, API calls, state
â”œâ”€â”€ css/
â”‚   â””â”€â”€ styles.css    # Animations, prose, code blocks
â”œâ”€â”€ .env.local        # API key reference (gitignored)
â””â”€â”€ .gitignore
```

## ğŸ”‘ API Keys

- **Groq** â€” Built-in key, works out of the box. Vision (LLaMA 4 Scout) + Whisper + text.
- **OpenRouter / Gemini / OpenAI / xAI** â€” Add in âš™ï¸ Settings.

## ğŸ–¼ï¸ Vision Details

| Provider | Image detail sent |
|----------|------------------|
| Groq (LLaMA 4) | No `detail` param (Groq doesn't support it) |
| OpenAI / OpenRouter | `detail: 'high'` for maximum quality |
| Gemini | Native format via OpenAI-compat endpoint |

## ğŸ“„ PDF Analysis

1. PDF.js extracts text client-side (up to 40 pages, 150k chars)
2. Text is wrapped with page markers and injected as structured context
3. Your selected text model (default: LLaMA 3.3 70B) reads and analyses it
